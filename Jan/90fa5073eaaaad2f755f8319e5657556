Right now, social media is impacting events, and billions of people, around the world.Yet, to a large extent, a small, exclusive club of nations still drives the debate on how to moderate content.  On 18th October 2020, the day of Guinea’s presidential election, the country’s media regulator suspended a news website for sharing information on election results on its Facebook page.
In the days that followed, the leader of Guinea’s opposition claimed victory, opposition protests were met with violence and access to social media and the internet was restricted.  



if (shouldRenderAd(true)) {
googletag.cmd.push(function () {
googletag.display("mobile-article-ad-1");
});
setInterval(function refreshAds() {
googletag.cmd.push(function adCommands() {
googletag.pubads().refresh([window.adSlots['mobile-article-ad-1']]);
});
}, 62000);
}



Two weeks later, during the US presidential election, the role of social media and claims of early victory also featured as major themes. But this time, tech companies, and the eyes of the world, were following closely.  
Right now, social media is impacting events, and billions of people, around the world. Yet, to a large extent, a small, exclusive club of nations still drives the debate on how to moderate content. 
Again and again, this follows the same pattern: outrage in the US and Europe, American tech companies scramble to react and the rest of the world deals with the results.  





Today, we need to open up this debate through a genuinely global approach which can improve content moderation for everyone.  
Instead of knee-jerk reactions to events in the US and Europe, we need to consider some difficult questions which affect us all.
Content moderation
How can we find solutions which will reshape the behaviour of tech companies in the long-term? On what basis can those companies make content decisions, which are seen as legitimate by users across the world? How can users be empowered to challenge tech companies’ decisions on their content?
International human rights standards are crucial to answering these questions. 



if (shouldRenderAd(true)) {
googletag.cmd.push(function () {
googletag.display("mobile-article-ad-2");
});
setInterval(function refreshAds() {
googletag.cmd.push(function adCommands() {
googletag.pubads().refresh([window.adSlots['mobile-article-ad-2']]);
});
}, 62000);
}



Built up over decades, through contributions from across the world, these put the big issues of content moderation front and centre. Providing a framework for considering how to balance a user’s right to free expression, against other human rights.  
The Oversight Board, a new, global body which I am part of, will deepen our understanding of how international human rights and content moderation come together.
We will not do this through theoretical discussion, but by deliberating real cases from around the world, including Africa. 
Together, our 20 members will make binding and independent decisions on the most challenging content issues on Facebook and Instagram. Instead of being driven by the news cycle, we will select cases to review, from the tens of thousands we have received, which present challenging questions. 
Later this month, we will announce our first case decisions. Over time, we hope that our decisions will give Facebook’s responses to content moderation questions a clearer basis in international human rights standards.  
While global standards matter, so do the people making the crucial decisions on content moderation. Right now, these are mostly drawn from North American and European elites, with a limited knowledge of issues facing people in other parts of the world. 



if (shouldRenderAd(true)) {
googletag.cmd.push(function () {
googletag.display("mobile-article-ad-3");
});
setInterval(function refreshAds() {
googletag.cmd.push(function adCommands() {
googletag.pubads().refresh([window.adSlots['mobile-article-ad-3']]);
});
}, 62000);
}



Global diversity
Instead, we must involve people from across the world, tapping into knowledge of local languages, debates and context which will lead to better decisions. 





At the Oversight Board, this global diversity is part of our DNA. 
Of the Board’s 20 members, three are from Africa: from Kenya, Cameroon and Ghana. Taken together, the Board’s members have lived in 27 countries and speak nearly 30 languages.  
Sensitivity to local context is also crucial to the Board. For each case, at least one panellist will be from the region involved. In our discussions, we will consider the context in which a post was made, as well as the significance of specific phrases. 
So often the social media debate revolves around the question ‘how can tech improve the world?’. Yet, when it comes to content moderation, we should be asking the opposite question: ‘how can the world improve tech?’ 
Building a genuinely global approach to content moderation means championing international human rights standards. It means valuing knowledge of local debates and involving people from the whole world, including Africa. 
Together, we can empower users to challenge decisions, ensure tech companies make better decisions, and give people around the world the confidence to connect.  



if (shouldRenderAd(true)) {
googletag.cmd.push(function () {
googletag.display("mobile-article-ad-4");
});
} Due to the curfew, sex workers have moved from their traditional haunts — bars and streets — to houses and on social media. Governors urged to prioritise pending bills and other statutory deductions. Positivity rate has dipped from a high of 20 percent several weeks ago to the current average of 2.8 percent.